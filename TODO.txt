# BIPHUB Pipeline Manager TODO List

## ✅ COMPLETED - Pipeline Designer GUI (Phase 1)
**Achievement**: Successfully implemented visual pipeline designer with Wails + React!

### What Was Built:
- **Backend (Go)**:
  - Complete data models (models.go) for visual pipeline representation
  - YAML parser (yaml_parser.go) - 100% compatible with run_pipeline.go format
  - CLI definitions manager (cli_definitions.go) for loading tool templates
  - Wails bindings (app.go) exposing backend to React frontend
  
- **Frontend (React + TypeScript)**:
  - 3-panel layout: CommandExplorer | Canvas | PropertiesPanel
  - React Flow integration for drag-and-drop node editing
  - Dark theme UI matching VS Code aesthetics
  - Socket-based node connections with real-time value editing
  - Zustand state management with backend integration
  
- **CLI Definitions**:
  - convert_to_tif.json - Image format conversion
  - segment_ernet.json - ER segmentation
  - mask_measure.json - Measurement extraction

### Build Output:
- ✅ Standalone executable: `pipeline-designer\build\bin\pipeline-designer.exe`
- ✅ Size: ~15-20MB (much smaller than Electron)
- ✅ No Node.js required for end users
- ✅ Native Windows performance with WebView2

## ✅ COMPLETED - Legacy YAML Import (2024-12)
**Achievement**: Designer can now import old pipeline YAML files without _designer_metadata!

### What Was Built:
- **legacy_importer.go**: Core import logic with strict validation
  - `ImportLegacyYAML()`: Main entry point for legacy conversion
  - `extractScriptPath()`: Extracts .py script paths from command arrays
  - `findCLIDefinitionByScript()`: Matches scripts to CLI JSON definitions
  - `populateSocketsFromYAMLArgs()`: Maps YAML args to node sockets
  - `PrintLegacyImportReport()`: Loud error reporting for validation failures
  
- **Modified yaml_parser.go**: Detects legacy YAMLs and routes to importer
  - Checks for missing `_designer_metadata` field
  - Finds cli_definitions path using os.Executable() pattern
  - Prints detailed import report with warnings/errors
  
- **Validation Features**:
  - ❌ NO SILENT ERRORS - Reports all unmatched arguments from YAML
  - ❌ NO MISSING ARGS - Reports all required arguments missing in YAML
  - ✅ Success counter shows how many steps imported cleanly
  - ✅ Automatic node layout: 450px horizontal spacing, left-to-right
  
- **Test File**: test_legacy_import.yaml
  - Example legacy pipeline with convert_to_tif + merge_channels
  - No _designer_metadata field
  - Should import with 2 nodes at (100, 200) and (550, 200)

### Testing Instructions:
1. Build Designer: `cd pipeline-designer ; go build`
2. Open Designer executable
3. Click "Load Pipeline"
4. Select `e:\Oyvind\OF_git\run_pipeline\test_legacy_import.yaml`
5. Check console output for import report
6. Verify 2 nodes appear on canvas in left-to-right layout
7. Check Properties Panel shows all socket values populated correctly

### Next Steps for Pipeline Designer:
1. **Test the GUI** - Open pipeline-designer.exe and verify:
   - Command Explorer loads 3 CLI definitions
   - Clicking a tool adds node to canvas
   - Nodes can be dragged around
   - Sockets can be edited in Properties Panel
   - Node connections work

2. **Implement File Operations**:
   - Add Load/Save buttons to App.tsx header
   - Wire up LoadPipeline(filePath) backend method
   - Wire up SavePipeline(pipeline, filePath) backend method
   - Test round-trip: load YAML → modify → save → verify output

3. **Add More CLI Definitions**:
   - Create JSON files for all standard_code/python/ modules
   - Auto-generate from Python docstrings and type hints
   - Add category icons and colors

4. **Test YAML Compatibility**:
   - Load existing pipeline_configs/*.yaml files
   - Verify node positions match expected layout
   - Test saving and running with run_pipeline.exe

5. **Phase 2 Features** (Future):
   - File browser for selecting input/output paths
   - Test runner UI showing real-time output
   - Environment manager for UV/Conda envs
   - Pipeline templates library

## Current Tasks  
- make all standard code

## Code Quality & Standards
- Add MIT license headers to all Python files in standard_code/python/
- Add MIT license headers to Go files (run_pipeline.go, go/find_anaconda_path/)
- Review and enhance type hints in all Python modules
- Add comprehensive docstrings to all functions following Google style
- Implement consistent error handling across all modules
- Add unit tests for critical functions

## Documentation
- Create comprehensive README.md with installation instructions
- Document all pipeline configuration options
- Create API documentation for Python modules
- Add usage examples for each supported analysis type
- Document environment setup procedures

## Environment & Dependencies
- **PRIORITY: Migrate to UV as primary package manager**
  - Convert all pipeline configs to use UV by default (like segment_ernet_uv.yaml)
  - Update Go orchestrator to prefer UV environments over Conda
  - Create UV lock files for reproducible dependency management
  - Test UV performance vs Conda for environment creation speed
  - Document UV migration benefits and usage patterns
- Keep Conda environments as backup/legacy support
  - Maintain existing conda_envs/ folder for compatibility
  - Update documentation to show both UV and Conda options
  - Test fallback mechanisms when UV is unavailable
- Test cross-platform compatibility (Windows/macOS/Linux) with UV
- Optimize UV environment creation and activation times
- Create hybrid approach: UV for most cases, Conda for complex dependencies

## Pipeline Improvements
- Add pipeline validation and dry-run capabilities
- Implement pipeline progress reporting
- Add support for pipeline parallelization
- Create template generator for new pipeline types
- Add pipeline performance benchmarking

## External Integrations
- Update ERnet integration to latest version
- Test and document Cellpose integration
- Improve ImageJ ROI export functionality
- Add support for additional segmentation tools

## Multi-Language Support (Universal Orchestration)
- **R scripts** for statistical analysis - create test examples with YAML variable passing
- **ImageJ macros** for image processing - debug current issues and create working examples
- **Shell commands** for file operations - demonstrate cross-platform shell script orchestration
- Create comprehensive test suite showing string, int, list, and complex data types
- Document variable type conversion between YAML and target languages
- make a yaml pipeline config that shows how to use all test scripts lke i have for test python

## Testing & Validation
- Create automated test suite for pipelines
- Add example datasets for testing
- Implement regression testing for output validation
- Create CI/CD pipeline for automated testing

## Add citations to the yaml config file 
- for each file in standard code check if a package or theory that needs citing is used.
- find a way to add this to the config file

## in run_pipeline.go add option for new %folder name% handles
- currently we are using %REPO% and %YAML% as relative paths. but lets add the option for more
- for example if %TEST_FOLDER% are found then look in the .env file for a tag called TEST_FOLDER.
- if not found then ask the user to either type in the path or add to env. if the path is not found then trow an error. 



## Mean10 not working