"""
Create per-group summary bar plots from distance heatmap quantification metrics.

This module reads TSV files generated by plot_distance_heatmap.py and creates
bar plots showing group comparisons for various measurements (distance spread,
center position, signal area, etc.) at specific timepoints.

Author: BIPHUB - Bioimage Informatics Hub, University of Oslo
License: MIT
"""

import os
import sys
import logging
import argparse
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
from typing import List, Dict, Optional, Tuple
import glob

# Local imports
try:
    from .. import bioimage_pipeline_utils as rp
except ImportError:
    # Fallback for when script is run directly (not as module)
    parent_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    sys.path.insert(0, parent_dir)
    import bioimage_pipeline_utils as rp


def plot_metric_per_group(
    df: pd.DataFrame,
    metric_column: str,
    timepoint: Optional[int] = None,
    output_path: Optional[str] = None,
    title: Optional[str] = None,
    ylabel: Optional[str] = None,
    show_individual_points: bool = True,
    point_alpha: float = 0.6,
    point_size: float = 50,
    bar_alpha: float = 0.7,
    error_bars: str = 'sem',
    figsize: Tuple[float, float] = (10, 6),
    color_palette: str = 'Set2',
    force_show: bool = False
) -> None:
    """
    Create a bar plot comparing a metric across experimental groups.
    
    Args:
        df: DataFrame with columns: Experimental_Group, Timepoint, and metric columns
        metric_column: Name of the column to plot (e.g., 'Distance_Spread')
        timepoint: Specific timepoint to plot. If None, averages across all timepoints.
        output_path: Optional path to save the plot
        title: Optional custom title
        ylabel: Optional custom y-axis label
        show_individual_points: If True, overlay individual data points on bars
        point_alpha: Alpha transparency for individual points (0-1)
        point_size: Size of individual points
        bar_alpha: Alpha transparency for bars (0-1)
        error_bars: Type of error bars: 'sem' (standard error), 'std' (standard deviation), 
                    'ci' (95% confidence interval), or None
        figsize: Figure size as (width, height)
        color_palette: Seaborn color palette name
        force_show: If True, display plot interactively even when saving
    """
    # Filter by timepoint if specified
    if timepoint is not None:
        df_plot = df[df['Timepoint'] == timepoint].copy()
        time_label = f"T={timepoint}"
    else:
        df_plot = df.copy()
        time_label = "All Timepoints"
    
    if len(df_plot) == 0:
        logging.warning(f"No data found for timepoint {timepoint}")
        return
    
    # Remove NaN values for this metric
    df_plot = df_plot.dropna(subset=[metric_column])
    
    if len(df_plot) == 0:
        logging.warning(f"No valid data for metric {metric_column}")
        return
    
    # Calculate summary statistics per group
    grouped = df_plot.groupby('Experimental_Group')[metric_column]
    means = grouped.mean()
    
    if error_bars == 'sem':
        errors = grouped.sem()
        error_label = 'SEM'
    elif error_bars == 'std':
        errors = grouped.std()
        error_label = 'SD'
    elif error_bars == 'ci':
        errors = grouped.apply(lambda x: 1.96 * x.sem())  # 95% CI
        error_label = '95% CI'
    else:
        errors = None
        error_label = ''
    
    # Get counts per group - count UNIQUE FILENAMES (number of images/samples), not rows
    # This ensures N reflects the number of independent samples, not timepoints
    counts = df_plot.groupby('Experimental_Group')['Filename'].nunique()
    
    # Sort groups alphabetically
    groups = sorted(means.index)
    
    # Create figure
    fig, ax = plt.subplots(figsize=figsize)
    
    # Get colors from palette
    colors = sns.color_palette(color_palette, len(groups))
    
    # Create bar plot
    x_pos = np.arange(len(groups))
    bars = ax.bar(x_pos, [means[g] for g in groups], 
                  yerr=[errors[g] if errors is not None else 0 for g in groups],
                  alpha=bar_alpha, color=colors, capsize=5, 
                  error_kw={'linewidth': 2, 'ecolor': 'black'})
    
    # Overlay individual points if requested
    if show_individual_points:
        for i, group in enumerate(groups):
            group_data = df_plot[df_plot['Experimental_Group'] == group][metric_column]
            # Add some jitter to x position for visibility
            x_jitter = np.random.normal(i, 0.04, size=len(group_data))
            ax.scatter(x_jitter, group_data, alpha=point_alpha, s=point_size, 
                      color='black', edgecolors='white', linewidth=0.5, zorder=3)
    
    # Customize plot
    ax.set_xticks(x_pos)
    ax.set_xticklabels(groups, fontsize=11, fontweight='bold')
    
    # Generate ylabel if not provided
    if ylabel is None:
        ylabel = metric_column.replace('_', ' ').title()
        if error_bars:
            ylabel += f'\n(Mean ± {error_label})'
    
    ax.set_ylabel(ylabel, fontsize=12, fontweight='bold')
    ax.set_xlabel('Experimental Group', fontsize=12, fontweight='bold')
    
    # Generate title if not provided
    if title is None:
        title = f'{metric_column.replace("_", " ").title()} by Group\n{time_label}'
    
    ax.set_title(title, fontsize=14, fontweight='bold', pad=15)
    
    # Add sample size annotations on bars
    for i, (group, bar) in enumerate(zip(groups, bars)):
        height = bar.get_height()
        error = errors[group] if errors is not None else 0
        ax.text(bar.get_x() + bar.get_width() / 2, height + error,
               f'n={counts[group]}',
               ha='center', va='bottom', fontsize=9, color='black')
    
    # Grid
    ax.grid(axis='y', alpha=0.3, linestyle='--')
    ax.set_axisbelow(True)
    
    # Adjust layout
    plt.tight_layout()
    
    # Save or show
    if output_path:
        output_dir = os.path.dirname(output_path)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)
        
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        logging.info(f"Saved plot to: {output_path}")
        
        if force_show:
            plt.show()
        else:
            plt.close()
    else:
        plt.show()


def plot_metric_timeseries_per_group(
    df: pd.DataFrame,
    metric_column: str,
    output_path: Optional[str] = None,
    title: Optional[str] = None,
    ylabel: Optional[str] = None,
    show_individual_points: bool = True,
    point_alpha: float = 0.3,
    point_size: float = 30,
    line_alpha: float = 0.8,
    line_width: float = 2.5,
    error_bars: str = 'sem',
    figsize: Tuple[float, float] = (12, 6),
    color_palette: str = 'Set2',
    force_show: bool = False
) -> None:
    """
    Create a line plot showing how a metric changes over time for each experimental group.
    
    Args:
        df: DataFrame with columns: Experimental_Group, Timepoint, and metric columns
        metric_column: Name of the column to plot (e.g., 'Distance_Spread')
        output_path: Optional path to save the plot
        title: Optional custom title
        ylabel: Optional custom y-axis label
        show_individual_points: If True, overlay individual data points on lines
        point_alpha: Alpha transparency for individual points (0-1)
        point_size: Size of individual points
        line_alpha: Alpha transparency for lines (0-1)
        line_width: Width of lines
        error_bars: Type of error bars: 'sem' (standard error), 'std' (standard deviation), 
                    'ci' (95% confidence interval), or None
        figsize: Figure size as (width, height)
        color_palette: Seaborn color palette name
        force_show: If True, display plot interactively even when saving
    """
    # Remove NaN values for this metric
    df_plot = df.dropna(subset=[metric_column, 'Timepoint']).copy()
    
    if len(df_plot) == 0:
        logging.warning(f"No valid data for metric {metric_column}")
        return
    
    # Get unique groups and timepoints
    groups = sorted(df_plot['Experimental_Group'].unique())
    timepoints = sorted(df_plot['Timepoint'].unique())
    
    if len(timepoints) < 2:
        logging.warning(f"Need at least 2 timepoints for time series plot. Found: {len(timepoints)}")
        return
    
    logging.info(f"Creating time series plot for {metric_column} with {len(groups)} groups and {len(timepoints)} timepoints")
    
    # Create figure
    fig, ax = plt.subplots(figsize=figsize)
    
    # Get colors from palette
    colors = sns.color_palette(color_palette, len(groups))
    
    # Plot each group
    for i, group in enumerate(groups):
        group_data = df_plot[df_plot['Experimental_Group'] == group]
        
        # Calculate summary statistics per timepoint
        grouped = group_data.groupby('Timepoint')[metric_column]
        means = grouped.mean()
        
        if error_bars == 'sem':
            errors = grouped.sem()
        elif error_bars == 'std':
            errors = grouped.std()
        elif error_bars == 'ci':
            errors = grouped.apply(lambda x: 1.96 * x.sem())  # 95% CI
        else:
            errors = None
        
        # Get counts per timepoint
        counts = grouped.count()
        
        # Get number of unique samples (filenames) in this group for the label
        n_samples = group_data['Filename'].nunique()
        
        # Plot line with error bars
        if errors is not None:
            ax.errorbar(means.index, means.values, yerr=errors.values,
                       label=f'{group} (n={n_samples})', 
                       color=colors[i], alpha=line_alpha, linewidth=line_width,
                       marker='o', markersize=8, capsize=4, capthick=2)
        else:
            ax.plot(means.index, means.values,
                   label=f'{group} (n={n_samples})', 
                   color=colors[i], alpha=line_alpha, linewidth=line_width,
                   marker='o', markersize=8)
        
        # Overlay individual points if requested
        if show_individual_points:
            for t in timepoints:
                t_data = group_data[group_data['Timepoint'] == t][metric_column]
                if len(t_data) > 0:
                    # Add some jitter to x position for visibility
                    x_jitter = np.random.normal(t, 0.1, size=len(t_data))
                    ax.scatter(x_jitter, t_data, alpha=point_alpha, s=point_size, 
                             color=colors[i], edgecolors='white', linewidth=0.5, zorder=3)
    
    # Customize plot
    ax.set_xlabel('Timepoint', fontsize=12, fontweight='bold')
    
    # Generate ylabel if not provided
    if ylabel is None:
        ylabel = metric_column.replace('_', ' ').title()
        if error_bars:
            error_label = {'sem': 'SEM', 'std': 'SD', 'ci': '95% CI'}[error_bars]
            ylabel += f'\n(Mean ± {error_label})'
    
    ax.set_ylabel(ylabel, fontsize=12, fontweight='bold')
    
    # Generate title if not provided
    if title is None:
        title = f'{metric_column.replace("_", " ").title()} Over Time by Group'
    
    ax.set_title(title, fontsize=14, fontweight='bold', pad=15)
    
    # Legend
    ax.legend(loc='best', framealpha=0.9, fontsize=10)
    
    # Grid
    ax.grid(axis='both', alpha=0.3, linestyle='--')
    ax.set_axisbelow(True)
    
    # Set x-axis to show only integer timepoints
    ax.set_xticks(timepoints)
    
    # Adjust layout
    plt.tight_layout()
    
    # Save or show
    if output_path:
        output_dir = os.path.dirname(output_path)
        if output_dir and not os.path.exists(output_dir):
            os.makedirs(output_dir, exist_ok=True)
        
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        logging.info(f"Saved time series plot to: {output_path}")
        
        if force_show:
            plt.show()
        else:
            plt.close()
    else:
        plt.show()


def plot_multiple_metrics_per_group(
    df: pd.DataFrame,
    metrics: List[str],
    timepoint: Optional[int] = None,
    output_folder: Optional[str] = None,
    base_filename: str = 'metric_comparison',
    **kwargs
) -> None:
    """
    Create multiple bar plots for different metrics.
    
    Args:
        df: DataFrame with columns: Experimental_Group, Timepoint, and metric columns
        metrics: List of metric column names to plot
        timepoint: Specific timepoint to plot. If None, averages across all timepoints.
        output_folder: Optional folder to save plots
        base_filename: Base filename for saved plots
        **kwargs: Additional arguments passed to plot_metric_per_group
    """
    for metric in metrics:
        if metric not in df.columns:
            logging.warning(f"Metric {metric} not found in DataFrame, skipping")
            continue
        
        if output_folder:
            output_path = os.path.join(
                output_folder, 
                f"{base_filename}_{metric}_T{timepoint if timepoint is not None else 'all'}.png"
            )
        else:
            output_path = None
        
        plot_metric_per_group(
            df, metric, timepoint=timepoint, output_path=output_path, **kwargs
        )


def plot_multiple_metrics_timeseries_per_group(
    df: pd.DataFrame,
    metrics: List[str],
    output_folder: Optional[str] = None,
    base_filename: str = 'timeseries',
    **kwargs
) -> None:
    """
    Create multiple time series line plots for different metrics.
    
    Args:
        df: DataFrame with columns: Experimental_Group, Timepoint, and metric columns
        metrics: List of metric column names to plot
        output_folder: Optional folder to save plots
        base_filename: Base filename for saved plots
        **kwargs: Additional arguments passed to plot_metric_timeseries_per_group
    """
    for metric in metrics:
        if metric not in df.columns:
            logging.warning(f"Metric {metric} not found in DataFrame, skipping")
            continue
        
        if output_folder:
            output_path = os.path.join(
                output_folder, 
                f"{base_filename}_{metric}.png"
            )
        else:
            output_path = None
        
        plot_metric_timeseries_per_group(
            df, metric, output_path=output_path, **kwargs
        )


def load_metrics_from_folder(
    folder_path: str,
    pattern: str = '*_metrics.tsv'
) -> pd.DataFrame:
    """
    Load all metrics TSV files from a folder and combine into single DataFrame.
    
    Args:
        folder_path: Path to folder containing metrics TSV files
        pattern: Glob pattern to match metrics files
    
    Returns:
        Combined DataFrame with all metrics
    """
    search_pattern = os.path.join(folder_path, pattern)
    tsv_files = glob.glob(search_pattern)
    
    if not tsv_files:
        raise FileNotFoundError(f"No metrics files found matching: {search_pattern}")
    
    logging.info(f"Found {len(tsv_files)} metrics file(s)")
    
    # Load and combine all TSV files
    dfs = []
    for tsv_file in tsv_files:
        try:
            df = pd.read_csv(tsv_file, sep='\t')
            dfs.append(df)
            logging.info(f"Loaded: {Path(tsv_file).name} ({len(df)} rows)")
        except Exception as e:
            logging.error(f"Error loading {tsv_file}: {e}")
            continue
    
    if not dfs:
        raise ValueError("No valid metrics files could be loaded")
    
    # Combine all dataframes
    combined_df = pd.concat(dfs, ignore_index=True)
    logging.info(f"Combined dataset: {len(combined_df)} total rows")
    
    return combined_df


def load_decay_summary_from_folder(
    folder_path: str,
    pattern: str = '*_decay_summary.tsv'
) -> pd.DataFrame:
    """
    Load all decay summary TSV files from a folder and combine into single DataFrame.
    
    Args:
        folder_path: Path to folder containing decay summary TSV files
        pattern: Glob pattern to match decay summary files
    
    Returns:
        Combined DataFrame with decay summary metrics (one row per file)
    """
    search_pattern = os.path.join(folder_path, pattern)
    tsv_files = glob.glob(search_pattern)
    
    if not tsv_files:
        logging.warning(f"No decay summary files found matching: {search_pattern}")
        return pd.DataFrame()  # Return empty DataFrame
    
    logging.info(f"Found {len(tsv_files)} decay summary file(s)")
    
    # Load and combine all TSV files
    dfs = []
    for tsv_file in tsv_files:
        try:
            df = pd.read_csv(tsv_file, sep='\t')
            dfs.append(df)
            logging.info(f"Loaded: {Path(tsv_file).name} ({len(df)} rows)")
        except Exception as e:
            logging.error(f"Error loading {tsv_file}: {e}")
            continue
    
    if not dfs:
        logging.warning("No valid decay summary files could be loaded")
        return pd.DataFrame()
    
    # Combine all dataframes
    combined_df = pd.concat(dfs, ignore_index=True)
    logging.info(f"Combined decay summary dataset: {len(combined_df)} total rows")
    
    return combined_df


def main():
    parser = argparse.ArgumentParser(
        description='Create per-group summary bar plots from distance heatmap quantification metrics',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Plot Distance_Spread at T=1 for all groups (bar plot)
  python plot_summary_per_group.py --input-folder ./quantification --metric Distance_Spread --timepoint 1
  
  # Plot multiple metrics at T=1
  python plot_summary_per_group.py --input-folder ./quantification --metric Distance_Spread Center_Distance Signal_Area_Bins --timepoint 1
  
  # Plot Distance_Spread over time for all groups (line plot - TIME SERIES)
  python plot_summary_per_group.py --input-folder ./quantification --metric Distance_Spread --timeseries --output-folder ./group_plots
  
  # Plot multiple metrics as time series
  python plot_summary_per_group.py --input-folder ./quantification --metric Distance_Spread Center_Distance Signal_Area_Bins --timeseries --output-folder ./group_plots
  
  # Save plots to output folder
  python plot_summary_per_group.py --input-folder ./quantification --metric Distance_Spread --timepoint 1 --output-folder ./group_plots
  
  # Plot average across all timepoints
  python plot_summary_per_group.py --input-folder ./quantification --metric Distance_Spread
  
  # Plot all decay metrics (signal duration, half-life, etc.)
  python plot_summary_per_group.py --input-folder ./quantification --metric decay --output-folder ./group_plots
  
  # Plot specific decay metrics
  python plot_summary_per_group.py --input-folder ./quantification --metric Signal_Duration_Timepoints Time_To_50_Percent --output-folder ./group_plots
  
  # Plot all available metrics (both per-timepoint and decay summaries)
  python plot_summary_per_group.py --input-folder ./quantification --metric all --timepoint 1 --output-folder ./group_plots
  
  # Plot all available metrics as time series
  python plot_summary_per_group.py --input-folder ./quantification --metric all --timeseries --output-folder ./group_plots
  
  # Customize appearance
  python plot_summary_per_group.py --input-folder ./quantification --metric Distance_Spread --timepoint 1 --color-palette Set1 --no-points
  
  # Use standard deviation instead of SEM for error bars
  python plot_summary_per_group.py --input-folder ./quantification --metric Distance_Spread --timepoint 1 --error-bars std
        """
    )
    
    parser.add_argument('--input-folder', type=str, required=True,
                       help='Folder containing *_metrics.tsv files from plot_distance_heatmap.py')
    parser.add_argument('--metric', type=str, nargs='+', required=True,
                       help='Metric(s) to plot: Distance_Spread, Center_Distance, Signal_Area_Bins, '
                            'Total_Intensity, Spread_Lower, Spread_Upper, '
                            'Signal_Duration_Timepoints, Time_To_50_Percent, Time_To_Disappearance, '
                            'Decay_Rate_Per_Timepoint, Initial_Intensity_T1, Intensity_T10, Intensity_T20, '
                            'or "all" for all metrics, or "decay" for all decay metrics')
    parser.add_argument('--timepoint', type=int, default=None,
                       help='Specific timepoint to plot (e.g., 1, 2, 3). If not specified, averages across all timepoints. '
                            'Note: decay metrics are per-file summaries and do not use this parameter. '
                            'Ignored if --timeseries is enabled.')
    parser.add_argument('--timeseries', action='store_true',
                       help='Create line plots showing metrics over time for each group (instead of bar plots at single timepoint). '
                            'This will plot ALL timepoints on X-axis with metric values on Y-axis, showing temporal dynamics.')
    parser.add_argument('--output-folder', type=str, default=None,
                       help='Folder to save plots. If not specified, displays interactively.')
    parser.add_argument('--no-points', action='store_true',
                       help='Do not show individual data points on bars')
    parser.add_argument('--point-alpha', type=float, default=0.6,
                       help='Alpha transparency for individual points (0-1, default: 0.6)')
    parser.add_argument('--point-size', type=float, default=50,
                       help='Size of individual points (default: 50)')
    parser.add_argument('--bar-alpha', type=float, default=0.7,
                       help='Alpha transparency for bars (0-1, default: 0.7)')
    parser.add_argument('--error-bars', type=str, default='sem',
                       choices=['sem', 'std', 'ci', 'none'],
                       help='Type of error bars: sem (standard error), std (standard deviation), '
                            'ci (95%% confidence interval), or none (default: sem)')
    parser.add_argument('--color-palette', type=str, default='Set2',
                       help='Seaborn color palette name (default: Set2)')
    parser.add_argument('--figsize', type=float, nargs=2, default=[10, 6],
                       help='Figure size as width height (default: 10 6)')
    parser.add_argument('--force-show-all', action='store_true',
                       help='Display all plots interactively even when saving to output folder')
    
    args = parser.parse_args()
    
    # Setup logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    # Load metrics
    df = load_metrics_from_folder(args.input_folder)
    
    # Filter out failed QC files if QC_Status column exists
    if 'QC_Status' in df.columns:
        initial_count = len(df)
        df = df[df['QC_Status'] != 'failed']
        filtered_count = initial_count - len(df)
        if filtered_count > 0:
            logging.info(f"Filtered out {filtered_count} rows with QC_Status='failed'")
    
    # Remove rows with missing Experimental_Group
    df = df.dropna(subset=['Experimental_Group'])
    
    if len(df) == 0:
        raise ValueError("No valid data after removing missing Experimental_Group values")
    
    # Load decay summary metrics (one row per file)
    df_decay = load_decay_summary_from_folder(args.input_folder)
    
    if not df_decay.empty:
        # Filter out failed QC files if QC_Status column exists
        if 'QC_Status' in df_decay.columns:
            initial_count = len(df_decay)
            df_decay = df_decay[df_decay['QC_Status'] != 'failed']
            filtered_count = initial_count - len(df_decay)
            if filtered_count > 0:
                logging.info(f"Filtered out {filtered_count} decay summary rows with QC_Status='failed'")
        
        # Remove rows with missing Experimental_Group
        df_decay = df_decay.dropna(subset=['Experimental_Group'])
        logging.info(f"Loaded {len(df_decay)} decay summary entries")
    
    # Get unique groups and timepoints
    groups = sorted(df['Experimental_Group'].unique())
    timepoints = sorted(df['Timepoint'].unique())
    
    logging.info(f"Experimental groups: {groups}")
    logging.info(f"Timepoints: {timepoints}")
    
    # Determine metrics to plot
    available_metrics = [
        'Center_Distance', 'Spread_Lower', 'Spread_Upper', 'Distance_Spread',
        'Signal_Area_Bins', 'Total_Intensity'
    ]
    
    # Decay metrics (from decay summary files)
    decay_metrics = [
        'Signal_Duration_Timepoints', 'Time_To_50_Percent', 'Time_To_Disappearance',
        'Decay_Rate_Per_Timepoint', 'Initial_Intensity_T1', 'Intensity_T10', 'Intensity_T20'
    ]
    
    if 'all' in args.metric:
        # Plot all available metrics from both sources
        metrics = [m for m in available_metrics if m in df.columns]
        if not df_decay.empty:
            metrics.extend([m for m in decay_metrics if m in df_decay.columns])
    elif 'decay' in args.metric:
        # Plot only decay metrics
        if df_decay.empty:
            logging.error("No decay summary files found. Cannot plot decay metrics.")
            return
        metrics = [m for m in decay_metrics if m in df_decay.columns]
    else:
        metrics = args.metric
    
    logging.info(f"Plotting metrics: {metrics}")
    
    # Convert error_bars argument
    error_bars = None if args.error_bars == 'none' else args.error_bars
    
    # Check if timeseries mode is enabled
    if args.timeseries:
        if args.timepoint is not None:
            logging.warning(f"--timepoint argument ignored in timeseries mode")
        
        # Create plots - separate decay metrics from per-timepoint metrics
        per_timepoint_metrics = [m for m in metrics if m in available_metrics]
        decay_summary_metrics = [m for m in metrics if m in decay_metrics]
        
        # Plot per-timepoint metrics as time series (from regular metrics files)
        if per_timepoint_metrics:
            logging.info(f"Plotting per-timepoint metrics as TIME SERIES: {per_timepoint_metrics}")
            plot_multiple_metrics_timeseries_per_group(
                df=df,
                metrics=per_timepoint_metrics,
                output_folder=args.output_folder,
                show_individual_points=not args.no_points,
                point_alpha=args.point_alpha,
                point_size=args.point_size,
                line_alpha=args.bar_alpha,  # Reuse bar_alpha for line_alpha
                error_bars=error_bars,
                figsize=tuple(args.figsize),
                color_palette=args.color_palette,
                force_show=args.force_show_all
            )
        
        # Decay summary metrics don't have time series (one value per file)
        if decay_summary_metrics and not df_decay.empty:
            logging.info(f"Decay metrics are per-file summaries, creating bar plots instead of time series: {decay_summary_metrics}")
            plot_multiple_metrics_per_group(
                df=df_decay,
                metrics=decay_summary_metrics,
                timepoint=None,  # Decay metrics don't use timepoint filtering
                output_folder=args.output_folder,
                base_filename='decay_summary',
                show_individual_points=not args.no_points,
                point_alpha=args.point_alpha,
                point_size=args.point_size,
                bar_alpha=args.bar_alpha,
                error_bars=error_bars,
                figsize=tuple(args.figsize),
                color_palette=args.color_palette,
                force_show=args.force_show_all
            )
    else:
        # Original bar plot mode
        # Create plots - separate decay metrics from per-timepoint metrics
        per_timepoint_metrics = [m for m in metrics if m in available_metrics]
        decay_summary_metrics = [m for m in metrics if m in decay_metrics]
        
        # Plot per-timepoint metrics (from regular metrics files)
        if per_timepoint_metrics:
            logging.info(f"Plotting per-timepoint metrics: {per_timepoint_metrics}")
            plot_multiple_metrics_per_group(
                df=df,
                metrics=per_timepoint_metrics,
                timepoint=args.timepoint,
                output_folder=args.output_folder,
                show_individual_points=not args.no_points,
                point_alpha=args.point_alpha,
                point_size=args.point_size,
                bar_alpha=args.bar_alpha,
                error_bars=error_bars,
                figsize=tuple(args.figsize),
                color_palette=args.color_palette,
                force_show=args.force_show_all
            )
        
        # Plot decay summary metrics (from decay summary files, one value per file)
        if decay_summary_metrics and not df_decay.empty:
            logging.info(f"Plotting decay summary metrics: {decay_summary_metrics}")
            plot_multiple_metrics_per_group(
                df=df_decay,
                metrics=decay_summary_metrics,
                timepoint=None,  # Decay metrics don't use timepoint filtering
                output_folder=args.output_folder,
                base_filename='decay_summary',
                show_individual_points=not args.no_points,
                point_alpha=args.point_alpha,
                point_size=args.point_size,
                bar_alpha=args.bar_alpha,
                error_bars=error_bars,
                figsize=tuple(args.figsize),
                color_palette=args.color_palette,
                force_show=args.force_show_all
            )
    
    logging.info("Processing complete!")


if __name__ == "__main__":
    main()
